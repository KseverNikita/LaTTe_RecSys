{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6zfbrvMoy9Ed"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Jd1axtgLy9Id"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, downvote_seen_items\n",
    "\n",
    "from polara.lib.tensor import hooi\n",
    "\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.linalg import solve_triangular, sqrtm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BDtwh0bdy9Mk"
   },
   "outputs": [],
   "source": [
    "def full_preproccessing():\n",
    "    data = get_movielens_data(include_time=True)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.8, interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = leave_one_out(\n",
    "    test_data, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = leave_one_out(\n",
    "        testset_, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_.userid.unique(), holdout_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "\n",
    "\n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min()\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = RecommenderData(training, \"userid\", \"movieid\", \"rating\")\n",
    "#data.prpeare_training_only()\n",
    "\n",
    "#data.set_test_data(testset=testset_valid, holdout=holdout_valid)\n",
    "\n",
    "#model.evaluate(switch_positive=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmYMpvcBy9QZ",
    "outputId": "bd702bab-2522-40a6-91df-ea8da2ceeede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 177 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description = full_preproccessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "from scipy.special import softmax\n",
    "\n",
    "def tf_model_build(config, data, data_description, testset, holdout, attention_matrix=np.array([])):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    if (attention_matrix.shape[0] == 0):\n",
    "        attention_matrix = form_attention_matrix(\n",
    "            data_description['n_ratings'],\n",
    "            **config['params'],\n",
    "            format = 'csr'\n",
    "        )\n",
    "        \n",
    "    attention_matrix = np.array(attention_matrix)\n",
    "\n",
    "    item_popularity = (\n",
    "        data[itemid]\n",
    "        .value_counts(sort=False)\n",
    "        .reindex(range(n_items))\n",
    "        .fillna(1)\n",
    "        .values\n",
    "    )\n",
    "    scaling_weights = get_scaling_weights(item_popularity, scaling=config[\"scaling\"])\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        u0, u1, u2 = sa_hooi(\n",
    "            idx, val, shape, config[\"mlrank\"],\n",
    "            attention_matrix = attention_matrix,\n",
    "            scaling_weights = scaling_weights,\n",
    "            testset = testset,\n",
    "            holdout = holdout,\n",
    "            data_description = data_description,\n",
    "            max_iters = config[\"num_iters\"],\n",
    "            parallel_ttm = True,\n",
    "            randomized = config[\"randomized\"],\n",
    "            growth_tol = config[\"growth_tol\"],\n",
    "            seed = config[\"seed\"],\n",
    "            iter_callback = None,\n",
    "        )\n",
    "    \n",
    "    return u0, u1, u2, attention_matrix    \n",
    "    \n",
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (30, 30, 5),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 5,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid)\n",
    "    useridx = data[userid]\n",
    "    itemidx = data[itemid].values\n",
    "    ratings = data[feedback].values\n",
    "    ratings = ratings - data_description['min_rating']\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    inv_attention = solve_triangular(attention_matrix, np.eye(5), lower=True)\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    #matrix_softmax = softmax(inv_attention.T @ feedback_factors)\n",
    "    matrix_softmax = inv_attention.T @ feedback_factors\n",
    "    #\n",
    "    if (context == \"5\"): # make softmax \n",
    "        inv_aT_feedback = matrix_softmax[-1, :]\n",
    "    elif (context == \"4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-2:, :], axis=0)\n",
    "    elif (context == \"3+4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-3:, :], axis=0)\n",
    "    #elif (context == \"2+3+4+5\"):\n",
    "    #    inv_aT_feedback = np.sum(matrix_softmax[-4:, :], axis=0)\n",
    "    elif (context == \"3+4+5-2-1\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-3:, :], axis=0) - np.sum(matrix_softmax[:2, :], axis=0)\n",
    "        \n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        attention_matrix @ feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1]) # sort by users\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        inv_aT_feedback,\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10, dcg=False):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    holdout_items = holdout[itemid].values\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    \n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    \n",
    "    # HR calculation\n",
    "    #hr = np.sum(hits_mask.any(axis=1)) / n_test_users\n",
    "    hr_pos = np.sum(hits_mask[pos_mask].any(axis=1)) / n_test_users\n",
    "    hr_neg = np.sum(hits_mask[neg_mask].any(axis=1)) / n_test_users\n",
    "    hr = hr_pos + hr_neg\n",
    "    \n",
    "    # MRR calculation\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    mrr_pos = np.sum(1 / pos_hit_rank) / n_test_users\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    mrr_neg = np.sum(1 / neg_hit_rank) / n_test_users\n",
    "    \n",
    "    # Matthews correlation\n",
    "    TP = np.sum(hits_mask[pos_mask]) # + \n",
    "    FP = np.sum(hits_mask[neg_mask]) # +\n",
    "    cond = (hits_mask.sum(axis = 1) == 0)\n",
    "    FN = np.sum(cond[pos_mask])\n",
    "    TN = np.sum(cond[neg_mask])\n",
    "    N = TP+FP+TN+FN\n",
    "    S = (TP+FN)/N\n",
    "    P = (TP+FP)/N\n",
    "    C = (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))\n",
    "    \n",
    "    # DCG calculation\n",
    "    if dcg:\n",
    "        pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "        neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "        ndcg = np.mean(1 / np.log2(pos_hit_rank+1))\n",
    "        ndcl = np.mean(1 / np.log2(neg_hit_rank+1))\n",
    "    \n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    if dcg:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C, ndcg, ndcl\n",
    "    else:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C\n",
    "\n",
    "def make_prediction(tf_scores, holdout, data_description, mode, context=\"\", print_mode=True):\n",
    "    if (mode and print_mode):\n",
    "        print(f\"for context {context} evaluation ({mode}): \\n\")\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout, data_description, topn=n)\n",
    "        if (print_mode):\n",
    "            print(f\"HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}\")\n",
    "            print(f\"HR_pos@{n} = {hr_pos:.4f}, HR_neg@{n} = {hr_neg:.4f}\")\n",
    "            print(f\"MRR_pos@{n} = {mrr_pos:.4f}, MRR_neg@{n} = {mrr_neg:.4f}\")\n",
    "            print(f\"Matthews@{n} = {C:.4f}\")\n",
    "            print(\"-------------------------------------\")\n",
    "        if (n == 10):\n",
    "            mrr10 = mrr\n",
    "            hr10 = hr\n",
    "            c10 = C\n",
    "    return mrr10, hr10, c10\n",
    "\n",
    "def valid_mlrank(mlrank):\n",
    "    '''\n",
    "    Only allow ranks that are suitable for truncated SVD computations\n",
    "    on unfolded compressed tensor (the result of ttm product in HOOI).\n",
    "    '''\n",
    "    #s, r1, r2, r3 = mlrank\n",
    "    s, r1, r3 = mlrank\n",
    "    r2 = r1\n",
    "    #print(s, r1, r2, r3)\n",
    "    return r1*r2 > r3 and r1*r3 > r2 and r2*r3 > r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "def full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix):\n",
    "\n",
    "    config[\"mlrank\"] = (30, 30, 5)\n",
    "    print(\"Starting pipeline...\")\n",
    "    print(\"Training with different context in progress...\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"3+4+5-2-1\"]:\n",
    "        tf_params = tf_model_build(config, training, data_description, testset_valid, holdout_valid, attention_matrix=attention_matrix)\n",
    "        seen_data = testset_valid\n",
    "        tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "        downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "        cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout_valid, data_description, \"Validation\", context)\n",
    "        print(\"------------------------------------------------------\")\n",
    "\n",
    "    print(f\"Tuning model for all contexts...\\n\")\n",
    "\n",
    "    rank_grid = []\n",
    "    for i in range(5, 10):\n",
    "        rank_grid.append(2 * 2 ** i)\n",
    "        rank_grid.append(3 * 2 ** i)\n",
    "    \n",
    "    rank_grid = np.array(rank_grid)\n",
    "    tf_hyper = {\n",
    "    'scaling': np.linspace(0, 2, 21),\n",
    "    'r1': rank_grid #np.arange(100, 220, 25),\n",
    "    #'r2': np.arange(50, 801, 25),\n",
    "    'r3': range(2, 6, 1),\n",
    "    }\n",
    "\n",
    "    grid, param_names = random_grid(tf_hyper, n=0)\n",
    "    tf_grid = [tuple(mlrank) for mlrank in grid if valid_mlrank(mlrank)]\n",
    "\n",
    "    hr_tf = {}\n",
    "    hr_pos_tf = {}\n",
    "    hr_neg_tf = {}\n",
    "    mrr_tf = {}\n",
    "    mrr_pos_tf = {}\n",
    "    mrr_neg_tf = {}\n",
    "    cov_tf = {}\n",
    "    C_tf = {}\n",
    "    \n",
    "    seen_data = testset_valid\n",
    "    \n",
    "    for mlrank in tqdm(tf_grid):\n",
    "        with io.capture_output() as captured:\n",
    "            r1, r3 = mlrank[1:]\n",
    "            cur_mlrank = tuple((r1, r1, r3))\n",
    "            config['mlrank'] = cur_mlrank\n",
    "            config['scaling'] = mlrank[0]\n",
    "            tf_params = tf_model_build(config, training, data_description, testset_valid, holdout_valid, attention_matrix=attention_matrix)\n",
    "            for context in [\"5\", \"4+5\", \"3+4+5\", \"3+4+5-2-1\"]:\n",
    "                tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "                downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "                tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "                \n",
    "                hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout_valid, data_description, topn=10)\n",
    "                hr_tf[(context, cur_mlrank, mlrank[0])] = hr\n",
    "                hr_pos_tf[(context, cur_mlrank, mlrank[0])] = hr_pos\n",
    "                hr_neg_tf[(context, cur_mlrank, mlrank[0])] = hr_neg\n",
    "                mrr_tf[(context, cur_mlrank, mlrank[0])] = mrr\n",
    "                mrr_pos_tf[(context, cur_mlrank, mlrank[0])] = mrr_pos\n",
    "                mrr_neg_tf[(context, cur_mlrank, mlrank[0])] = mrr_neg\n",
    "                cov_tf[(context, cur_mlrank, mlrank[0])] = cov\n",
    "                C_tf[(context, cur_mlrank, mlrank[0])] = C\n",
    "\n",
    "    print(f'Best HR={pd.Series(hr_tf).max():.4f} achieved with context {pd.Series(hr_tf).idxmax()[0]} and mlrank = {pd.Series(hr_tf).idxmax()[1]} and scale factor = {pd.Series(hr_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_pos={pd.Series(hr_pos_tf).max():.4f} achieved with context {pd.Series(hr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(hr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(hr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_neg={pd.Series(hr_neg_tf).min():.4f} achieved with context {pd.Series(hr_neg_tf).idxmin()[0]} and mlrank = {pd.Series(hr_neg_tf).idxmin()[1]} and scale factor = {pd.Series(hr_neg_tf).idxmin()[2]}')\n",
    "    \n",
    "    print(f'Best MRR={pd.Series(mrr_tf).max():.4f} achieved with context {pd.Series(mrr_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR_pos={pd.Series(mrr_pos_tf).max():.4f} achieved with context {pd.Series(mrr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR_neg={pd.Series(mrr_neg_tf).min():.4f} achieved with context {pd.Series(mrr_neg_tf).idxmin()[0]} and mlrank = {pd.Series(mrr_neg_tf).idxmin()[1]} and scale factor = {pd.Series(mrr_neg_tf).idxmin()[2]}')\n",
    "    \n",
    "    print(f'Best Matthews={pd.Series(C_tf).max():.4f} achieved with context {pd.Series(C_tf).idxmax()[0]} and mlrank = {pd.Series(C_tf).idxmax()[1]} and scale factor = {pd.Series(C_tf).idxmax()[2]}')\n",
    "                          \n",
    "    print(f'COV={pd.Series(cov_tf)[pd.Series(C_tf).idxmax()]:.4f} (based on best Matthews value)')\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Evaluation of the best model on test holdout in progress...\\n\")\n",
    "    \n",
    "    print(\"Best by MRR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(mrr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by HR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(hr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by Matthews@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(C_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(C_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(C_tf).idxmax()[0])\n",
    "    print(\"Pipeline ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.85, 0.2 , 0.01, 0.01],\n",
       "       [0.85, 1.  , 0.7 , 0.2 , 0.01],\n",
       "       [0.2 , 0.7 , 1.  , 0.65, 0.5 ],\n",
       "       [0.01, 0.2 , 0.65, 1.  , 0.85],\n",
       "       [0.01, 0.01, 0.5 , 0.85, 1.  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = np.array([[1.0, 0.85, 0.2, 0.01, 0.01], [0.85, 1.0, 0.7, 0.2, 0.01], [0.2, 0.7, 1.0, 0.65, 0.5], [0.01, 0.2, 0.65, 1.0, 0.85], [0.01, 0.01, 0.5, 0.85, 1.0]])\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0422, MRR@5 = 0.0197, Coverage@5 = 0.1199\n",
      "HR_pos@5 = 0.0411, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0194, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0787\n",
      "-------------------------------------\n",
      "HR@10 = 0.0610, MRR@10 = 0.0222, Coverage@10 = 0.1670\n",
      "HR_pos@10 = 0.0592, HR_neg@10 = 0.0018\n",
      "MRR_pos@10 = 0.0218, MRR_neg@10 = 0.0003\n",
      "Matthews@10 = 0.0947\n",
      "-------------------------------------\n",
      "HR@20 = 0.1138, MRR@20 = 0.0258, Coverage@20 = 0.2278\n",
      "HR_pos@20 = 0.1044, HR_neg@20 = 0.0094\n",
      "MRR_pos@20 = 0.0249, MRR_neg@20 = 0.0008\n",
      "Matthews@20 = 0.0818\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0370, MRR@5 = 0.0197, Coverage@5 = 0.1280\n",
      "HR_pos@5 = 0.0352, HR_neg@5 = 0.0018\n",
      "MRR_pos@5 = 0.0183, MRR_neg@5 = 0.0015\n",
      "Matthews@5 = 0.0630\n",
      "-------------------------------------\n",
      "HR@10 = 0.0610, MRR@10 = 0.0230, Coverage@10 = 0.1715\n",
      "HR_pos@10 = 0.0575, HR_neg@10 = 0.0035\n",
      "MRR_pos@10 = 0.0213, MRR_neg@10 = 0.0017\n",
      "Matthews@10 = 0.0751\n",
      "-------------------------------------\n",
      "HR@20 = 0.1202, MRR@20 = 0.0269, Coverage@20 = 0.2342\n",
      "HR_pos@20 = 0.1091, HR_neg@20 = 0.0111\n",
      "MRR_pos@20 = 0.0247, MRR_neg@20 = 0.0022\n",
      "Matthews@20 = 0.0743\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0375, MRR@5 = 0.0209, Coverage@5 = 0.1392\n",
      "HR_pos@5 = 0.0346, HR_neg@5 = 0.0029\n",
      "MRR_pos@5 = 0.0186, MRR_neg@5 = 0.0023\n",
      "Matthews@5 = 0.0474\n",
      "-------------------------------------\n",
      "HR@10 = 0.0663, MRR@10 = 0.0247, Coverage@10 = 0.1835\n",
      "HR_pos@10 = 0.0604, HR_neg@10 = 0.0059\n",
      "MRR_pos@10 = 0.0219, MRR_neg@10 = 0.0027\n",
      "Matthews@10 = 0.0565\n",
      "-------------------------------------\n",
      "HR@20 = 0.1161, MRR@20 = 0.0281, Coverage@20 = 0.2429\n",
      "HR_pos@20 = 0.1038, HR_neg@20 = 0.0123\n",
      "MRR_pos@20 = 0.0249, MRR_neg@20 = 0.0032\n",
      "Matthews@20 = 0.0598\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 2+3+4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0387, MRR@5 = 0.0210, Coverage@5 = 0.1425\n",
      "HR_pos@5 = 0.0340, HR_neg@5 = 0.0047\n",
      "MRR_pos@5 = 0.0178, MRR_neg@5 = 0.0032\n",
      "Matthews@5 = 0.0250\n",
      "-------------------------------------\n",
      "HR@10 = 0.0657, MRR@10 = 0.0245, Coverage@10 = 0.1924\n",
      "HR_pos@10 = 0.0598, HR_neg@10 = 0.0059\n",
      "MRR_pos@10 = 0.0211, MRR_neg@10 = 0.0034\n",
      "Matthews@10 = 0.0557\n",
      "-------------------------------------\n",
      "HR@20 = 0.1185, MRR@20 = 0.0280, Coverage@20 = 0.2526\n",
      "HR_pos@20 = 0.1032, HR_neg@20 = 0.0152\n",
      "MRR_pos@20 = 0.0240, MRR_neg@20 = 0.0040\n",
      "Matthews@20 = 0.0383\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 3+4+5-2-1 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0387, MRR@5 = 0.0192, Coverage@5 = 0.1333\n",
      "HR_pos@5 = 0.0370, HR_neg@5 = 0.0018\n",
      "MRR_pos@5 = 0.0183, MRR_neg@5 = 0.0010\n",
      "Matthews@5 = 0.0657\n",
      "-------------------------------------\n",
      "HR@10 = 0.0610, MRR@10 = 0.0222, Coverage@10 = 0.1782\n",
      "HR_pos@10 = 0.0581, HR_neg@10 = 0.0029\n",
      "MRR_pos@10 = 0.0211, MRR_neg@10 = 0.0011\n",
      "Matthews@10 = 0.0816\n",
      "-------------------------------------\n",
      "HR@20 = 0.1120, MRR@20 = 0.0257, Coverage@20 = 0.2404\n",
      "HR_pos@20 = 0.1044, HR_neg@20 = 0.0076\n",
      "MRR_pos@20 = 0.0242, MRR_neg@20 = 0.0015\n",
      "Matthews@20 = 0.0948\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [2:28:13<00:00, 21.17s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0997 achieved with context 2+3+4+5 and mlrank = (200, 200, 4) and scale factor = 0.7000000000000001\n",
      "Best HR_pos=0.0856 achieved with context 2+3+4+5 and mlrank = (200, 200, 4) and scale factor = 0.8\n",
      "Best HR_neg=0.0023 achieved with context 5 and mlrank = (175, 175, 2) and scale factor = 2.0\n",
      "Best MRR=0.0357 achieved with context 2+3+4+5 and mlrank = (125, 125, 5) and scale factor = 0.0\n",
      "Best MRR_pos=0.0329 achieved with context 3+4+5 and mlrank = (175, 175, 3) and scale factor = 0.0\n",
      "Best MRR_neg=0.0004 achieved with context 5 and mlrank = (100, 100, 4) and scale factor = 0.8\n",
      "Best Matthews=0.1120 achieved with context 5 and mlrank = (100, 100, 5) and scale factor = 0.9\n",
      "COV=0.2312 (based on best Matthews value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n",
      "\n",
      "Best by MRR@10:\n",
      "\n",
      "for context 3+4+5 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0362, MRR@5 = 0.0175, Coverage@5 = 0.2161\n",
      "HR_pos@5 = 0.0305, HR_neg@5 = 0.0058\n",
      "MRR_pos@5 = 0.0148, MRR_neg@5 = 0.0026\n",
      "Matthews@5 = 0.0079\n",
      "-------------------------------------\n",
      "HR@10 = 0.0615, MRR@10 = 0.0209, Coverage@10 = 0.2708\n",
      "HR_pos@10 = 0.0546, HR_neg@10 = 0.0069\n",
      "MRR_pos@10 = 0.0182, MRR_neg@10 = 0.0028\n",
      "Matthews@10 = 0.0419\n",
      "-------------------------------------\n",
      "HR@20 = 0.1052, MRR@20 = 0.0239, Coverage@20 = 0.3388\n",
      "HR_pos@20 = 0.0932, HR_neg@20 = 0.0121\n",
      "MRR_pos@20 = 0.0208, MRR_neg@20 = 0.0031\n",
      "Matthews@20 = 0.0538\n",
      "-------------------------------------\n",
      "---------------------------------------------------------\n",
      "Best by HR@10:\n",
      "\n",
      "for context 2+3+4+5 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0334, MRR@5 = 0.0159, Coverage@5 = 0.2334\n",
      "HR_pos@5 = 0.0282, HR_neg@5 = 0.0052\n",
      "MRR_pos@5 = 0.0140, MRR_neg@5 = 0.0018\n",
      "Matthews@5 = 0.0093\n",
      "-------------------------------------\n",
      "HR@10 = 0.0581, MRR@10 = 0.0190, Coverage@10 = 0.2842\n",
      "HR_pos@10 = 0.0512, HR_neg@10 = 0.0069\n",
      "MRR_pos@10 = 0.0170, MRR_neg@10 = 0.0021\n",
      "Matthews@10 = 0.0363\n",
      "-------------------------------------\n",
      "HR@20 = 0.1093, MRR@20 = 0.0225, Coverage@20 = 0.3555\n",
      "HR_pos@20 = 0.0955, HR_neg@20 = 0.0138\n",
      "MRR_pos@20 = 0.0200, MRR_neg@20 = 0.0025\n",
      "Matthews@20 = 0.0442\n",
      "-------------------------------------\n",
      "---------------------------------------------------------\n",
      "Best by Matthews@10:\n",
      "\n",
      "for context 5 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0362, MRR@5 = 0.0196, Coverage@5 = 0.1645\n",
      "HR_pos@5 = 0.0345, HR_neg@5 = 0.0017\n",
      "MRR_pos@5 = 0.0191, MRR_neg@5 = 0.0005\n",
      "Matthews@5 = 0.0647\n",
      "-------------------------------------\n",
      "HR@10 = 0.0610, MRR@10 = 0.0227, Coverage@10 = 0.2114\n",
      "HR_pos@10 = 0.0564, HR_neg@10 = 0.0046\n",
      "MRR_pos@10 = 0.0219, MRR_neg@10 = 0.0008\n",
      "Matthews@10 = 0.0663\n",
      "-------------------------------------\n",
      "HR@20 = 0.1070, MRR@20 = 0.0258, Coverage@20 = 0.2797\n",
      "HR_pos@20 = 0.1024, HR_neg@20 = 0.0046\n",
      "MRR_pos@20 = 0.0250, MRR_neg@20 = 0.0008\n",
      "Matthews@20 = 0.1197\n",
      "-------------------------------------\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "config[\"params\"] = {}\n",
    "attention_matrix = sqrtm(similarity_matrix).real\n",
    "#without sigmoid\n",
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid)\n",
    "    useridx = data[userid]\n",
    "    itemidx = data[itemid].values\n",
    "    ratings = data[feedback].values\n",
    "    ratings = ratings - data_description['min_rating']\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    inv_attention = solve_triangular(attention_matrix, np.eye(5), lower=True)\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    matrix_softmax = softmax(inv_attention.T @ feedback_factors)\n",
    "    #matrix_softmax = inv_attention.T @ feedback_factors\n",
    "    #\n",
    "    if (context == \"5\"): # make softmax \n",
    "        inv_aT_feedback = matrix_softmax[-1, :]\n",
    "    elif (context == \"4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-2:, :], axis=0)\n",
    "    elif (context == \"3+4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-3:, :], axis=0)\n",
    "    elif (context == \"2+3+4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-4:, :], axis=0)\n",
    "    elif (context == \"3+4+5-2-1\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[-3:, :], axis=0) - np.sum(matrix_softmax[:2, :], axis=0)\n",
    "        \n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        attention_matrix @ feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1]) # sort by users\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        inv_aT_feedback,\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0358, MRR@5 = 0.0186, Coverage@5 = 0.1160\n",
      "HR_pos@5 = 0.0358, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0186, MRR_neg@5 = 0.0000\n",
      "Matthews@5 = 0.0865\n",
      "-------------------------------------\n",
      "HR@10 = 0.0598, MRR@10 = 0.0218, Coverage@10 = 0.1559\n",
      "HR_pos@10 = 0.0581, HR_neg@10 = 0.0018\n",
      "MRR_pos@10 = 0.0216, MRR_neg@10 = 0.0002\n",
      "Matthews@10 = 0.0934\n",
      "-------------------------------------\n",
      "HR@20 = 0.1114, MRR@20 = 0.0253, Coverage@20 = 0.2131\n",
      "HR_pos@20 = 0.1062, HR_neg@20 = 0.0053\n",
      "MRR_pos@20 = 0.0249, MRR_neg@20 = 0.0004\n",
      "Matthews@20 = 0.1141\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0346, MRR@5 = 0.0175, Coverage@5 = 0.1157\n",
      "HR_pos@5 = 0.0346, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0175, MRR_neg@5 = 0.0000\n",
      "Matthews@5 = 0.0850\n",
      "-------------------------------------\n",
      "HR@10 = 0.0604, MRR@10 = 0.0208, Coverage@10 = 0.1559\n",
      "HR_pos@10 = 0.0592, HR_neg@10 = 0.0012\n",
      "MRR_pos@10 = 0.0207, MRR_neg@10 = 0.0001\n",
      "Matthews@10 = 0.1007\n",
      "-------------------------------------\n",
      "HR@20 = 0.1067, MRR@20 = 0.0240, Coverage@20 = 0.2122\n",
      "HR_pos@20 = 0.1015, HR_neg@20 = 0.0053\n",
      "MRR_pos@20 = 0.0236, MRR_neg@20 = 0.0004\n",
      "Matthews@20 = 0.1094\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0358, MRR@5 = 0.0185, Coverage@5 = 0.1166\n",
      "HR_pos@5 = 0.0358, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0185, MRR_neg@5 = 0.0000\n",
      "Matthews@5 = 0.0865\n",
      "-------------------------------------\n",
      "HR@10 = 0.0616, MRR@10 = 0.0218, Coverage@10 = 0.1576\n",
      "HR_pos@10 = 0.0604, HR_neg@10 = 0.0012\n",
      "MRR_pos@10 = 0.0216, MRR_neg@10 = 0.0001\n",
      "Matthews@10 = 0.1019\n",
      "-------------------------------------\n",
      "HR@20 = 0.1085, MRR@20 = 0.0249, Coverage@20 = 0.2142\n",
      "HR_pos@20 = 0.1032, HR_neg@20 = 0.0053\n",
      "MRR_pos@20 = 0.0245, MRR_neg@20 = 0.0004\n",
      "Matthews@20 = 0.1112\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 2+3+4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0364, MRR@5 = 0.0184, Coverage@5 = 0.1171\n",
      "HR_pos@5 = 0.0358, HR_neg@5 = 0.0006\n",
      "MRR_pos@5 = 0.0181, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0788\n",
      "-------------------------------------\n",
      "HR@10 = 0.0610, MRR@10 = 0.0216, Coverage@10 = 0.1559\n",
      "HR_pos@10 = 0.0587, HR_neg@10 = 0.0023\n",
      "MRR_pos@10 = 0.0211, MRR_neg@10 = 0.0005\n",
      "Matthews@10 = 0.0882\n",
      "-------------------------------------\n",
      "HR@20 = 0.1103, MRR@20 = 0.0249, Coverage@20 = 0.2133\n",
      "HR_pos@20 = 0.1038, HR_neg@20 = 0.0065\n",
      "MRR_pos@20 = 0.0241, MRR_neg@20 = 0.0008\n",
      "Matthews@20 = 0.1029\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 3+4+5-2-1 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0346, MRR@5 = 0.0183, Coverage@5 = 0.1152\n",
      "HR_pos@5 = 0.0346, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0183, MRR_neg@5 = 0.0000\n",
      "Matthews@5 = 0.0850\n",
      "-------------------------------------\n",
      "HR@10 = 0.0604, MRR@10 = 0.0216, Coverage@10 = 0.1567\n",
      "HR_pos@10 = 0.0592, HR_neg@10 = 0.0012\n",
      "MRR_pos@10 = 0.0215, MRR_neg@10 = 0.0001\n",
      "Matthews@10 = 0.1007\n",
      "-------------------------------------\n",
      "HR@20 = 0.1056, MRR@20 = 0.0247, Coverage@20 = 0.2150\n",
      "HR_pos@20 = 0.1021, HR_neg@20 = 0.0035\n",
      "MRR_pos@20 = 0.0244, MRR_neg@20 = 0.0003\n",
      "Matthews@20 = 0.1236\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [2:50:41<00:00, 24.38s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0974 achieved with context 5 and mlrank = (175, 175, 4) and scale factor = 1.1\n",
      "Best HR_pos=0.0856 achieved with context 5 and mlrank = (200, 200, 4) and scale factor = 1.4000000000000001\n",
      "Best HR_neg=0.0029 achieved with context 3+4+5-2-1 and mlrank = (125, 125, 3) and scale factor = 1.9000000000000001\n",
      "Best MRR=0.0359 achieved with context 5 and mlrank = (175, 175, 3) and scale factor = 0.0\n",
      "Best MRR_pos=0.0319 achieved with context 3+4+5-2-1 and mlrank = (200, 200, 5) and scale factor = 0.2\n",
      "Best MRR_neg=0.0005 achieved with context 5 and mlrank = (100, 100, 2) and scale factor = 1.8\n",
      "Best Matthews=0.0988 achieved with context 3+4+5-2-1 and mlrank = (200, 200, 5) and scale factor = 1.9000000000000001\n",
      "COV=0.2669 (based on best Matthews value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n",
      "\n",
      "Best by MRR@10:\n",
      "\n",
      "for context 3+4+5-2-1 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0380, MRR@5 = 0.0165, Coverage@5 = 0.2315\n",
      "HR_pos@5 = 0.0316, HR_neg@5 = 0.0063\n",
      "MRR_pos@5 = 0.0144, MRR_neg@5 = 0.0021\n",
      "Matthews@5 = 0.0040\n",
      "-------------------------------------\n",
      "HR@10 = 0.0587, MRR@10 = 0.0193, Coverage@10 = 0.2909\n",
      "HR_pos@10 = 0.0506, HR_neg@10 = 0.0081\n",
      "MRR_pos@10 = 0.0169, MRR_neg@10 = 0.0024\n",
      "Matthews@10 = 0.0243\n",
      "-------------------------------------\n",
      "HR@20 = 0.1121, MRR@20 = 0.0228, Coverage@20 = 0.3678\n",
      "HR_pos@20 = 0.0995, HR_neg@20 = 0.0127\n",
      "MRR_pos@20 = 0.0201, MRR_neg@20 = 0.0027\n",
      "Matthews@20 = 0.0575\n",
      "-------------------------------------\n",
      "---------------------------------------------------------\n",
      "Best by HR@10:\n",
      "\n",
      "for context 5 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0408, MRR@5 = 0.0196, Coverage@5 = 0.2342\n",
      "HR_pos@5 = 0.0362, HR_neg@5 = 0.0046\n",
      "MRR_pos@5 = 0.0178, MRR_neg@5 = 0.0018\n",
      "Matthews@5 = 0.0335\n",
      "-------------------------------------\n",
      "HR@10 = 0.0690, MRR@10 = 0.0232, Coverage@10 = 0.2970\n",
      "HR_pos@10 = 0.0621, HR_neg@10 = 0.0069\n",
      "MRR_pos@10 = 0.0211, MRR_neg@10 = 0.0021\n",
      "Matthews@10 = 0.0533\n",
      "-------------------------------------\n",
      "HR@20 = 0.1196, MRR@20 = 0.0266, Coverage@20 = 0.3667\n",
      "HR_pos@20 = 0.1070, HR_neg@20 = 0.0127\n",
      "MRR_pos@20 = 0.0241, MRR_neg@20 = 0.0025\n",
      "Matthews@20 = 0.0665\n",
      "-------------------------------------\n",
      "---------------------------------------------------------\n",
      "Best by Matthews@10:\n",
      "\n",
      "for context 3+4+5-2-1 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0380, MRR@5 = 0.0165, Coverage@5 = 0.2315\n",
      "HR_pos@5 = 0.0316, HR_neg@5 = 0.0063\n",
      "MRR_pos@5 = 0.0144, MRR_neg@5 = 0.0021\n",
      "Matthews@5 = 0.0040\n",
      "-------------------------------------\n",
      "HR@10 = 0.0587, MRR@10 = 0.0193, Coverage@10 = 0.2909\n",
      "HR_pos@10 = 0.0506, HR_neg@10 = 0.0081\n",
      "MRR_pos@10 = 0.0169, MRR_neg@10 = 0.0024\n",
      "Matthews@10 = 0.0243\n",
      "-------------------------------------\n",
      "HR@20 = 0.1121, MRR@20 = 0.0228, Coverage@20 = 0.3678\n",
      "HR_pos@20 = 0.0995, HR_neg@20 = 0.0127\n",
      "MRR_pos@20 = 0.0201, MRR_neg@20 = 0.0027\n",
      "Matthews@20 = 0.0575\n",
      "-------------------------------------\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "config[\"params\"] = {}\n",
    "#with sigmoid\n",
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sigmoid without normalization (scale factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYMZzRsB-lwT"
   },
   "source": [
    "## Rating distribution attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOW0iu_z-lwV",
    "outputId": "f9e5e9c0-4737-4b68-ed50-079df0d9121c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.056644931644931645,\n",
       " 0.10500693000693001,\n",
       " 0.25943898443898444,\n",
       " 0.3442087192087192,\n",
       " 0.2347004347004347]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dist = []\n",
    "\n",
    "total_cnt = training.shape[0]\n",
    "\n",
    "for i in range(5):\n",
    "    val = training.query(f'rating == {i + 1}').count()[0] / total_cnt\n",
    "    \n",
    "    rating_dist.append(val)\n",
    "\n",
    "rating_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cGm3uxPQK-4",
    "outputId": "a0465ef1-27b6-48ac-bb3c-e89f10000879"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[        inf,  1.17126946,  0.27932245,  0.19698214,  0.31813076],\n",
       "       [ 2.17126946,         inf,  0.67995553,  0.4389889 ,  0.8096545 ],\n",
       "       [ 1.27932245,  1.67995553,         inf,  3.06051429, 10.48723499],\n",
       "       [ 1.19698214,  1.4389889 ,  4.06051429,         inf,  3.14322081],\n",
       "       [ 1.31813076,  1.8096545 ,  9.48723499,  2.14322081,         inf]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        rat_dist_matrix[i, j] = rating_dist[i] / abs(rating_dist[i] - rating_dist[j])\n",
    "        #rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "\n",
    "rat_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVtjj-UD-lwW"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        diff = abs(rating_dist[i] - rating_dist[j])\n",
    "        rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "        \n",
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)\n",
    "#rat_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qcbsCWe-lwZ",
    "outputId": "8f1da19a-e989-4a15-d5ae-64fc43e5683c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 445.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 = 0.0144, Coverage@5 = 0.1117, nDCG@5 = 0.016772111754940346, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0466, MRR@10 = 0.0175, Coverage@10 = 0.1546, nDCG@10 = 0.023598806239983595, nDCL@10 = 0.0005780450156306099\n",
      "Test : HR@20 = 0.0783, MRR@20 = 0.0197, Coverage@20 = 0.2036, nDCG@20 = 0.03118319086912337, nDCL@20 = 0.0010092849309640722\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 421.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0200, Coverage@5 = 0.1109, nDCG@5 = 0.02287084881401924, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0642, MRR@10 = 0.0240, Coverage@10 = 0.1499, nDCG@10 = 0.03215653999889215, nDCL@10 = 0.001030494339396439\n",
      "Test : HR@20 = 0.1091, MRR@20 = 0.0270, Coverage@20 = 0.2014, nDCG@20 = 0.042042408086102726, nDCL@20 = 0.002324415387296944\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 430.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0352, MRR@5 = 0.0200, Coverage@5 = 0.1131, nDCG@5 = 0.023292283101531776, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0774, MRR@10 = 0.0255, Coverage@10 = 0.1508, nDCG@10 = 0.035593016466947444, nDCL@10 = 0.0015958437691679919\n",
      "Test : HR@20 = 0.1223, MRR@20 = 0.0283, Coverage@20 = 0.2044, nDCG@20 = 0.04514020087027024, nDCL@20 = 0.003077443022063615\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 428.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0369, MRR@5 = 0.0199, Coverage@5 = 0.1142, nDCG@5 = 0.023307446744329403, nDCL@5 = 0.0007190231884854308\n",
      "Test : HR@10 = 0.0712, MRR@10 = 0.0242, Coverage@10 = 0.1535, nDCG@10 = 0.033375587900277, nDCL@10 = 0.0015386887550953153\n",
      "Test : HR@20 = 0.1187, MRR@20 = 0.0274, Coverage@20 = 0.2052, nDCG@20 = 0.043284447809058275, nDCL@20 = 0.0034691192822309458\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 402.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0172, Coverage@5 = 0.1144, nDCG@5 = 0.02074601094985069, nDCL@5 = 0.0003787832524831953\n",
      "Test : HR@10 = 0.0712, MRR@10 = 0.0221, Coverage@10 = 0.1552, nDCG@10 = 0.03205373289389733, nDCL@10 = 0.0012005394879658672\n",
      "Test : HR@20 = 0.1214, MRR@20 = 0.0255, Coverage@20 = 0.2028, nDCG@20 = 0.04261636016198688, nDCL@20 = 0.0031542602033563837\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:30<00:00, 10.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 45, 5)\n",
      "Best MRR=0.0306 achieved with mlrank=(55, 55, 5)\n",
      "COV=0.1772 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 344.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0143, Coverage@5 = 0.1348, nDCG@5 = 0.016939382722254145, nDCL@5 = 0.0016141705594669602\n",
      "Test : HR@10 = 0.0580, MRR@10 = 0.0179, Coverage@10 = 0.1774, nDCG@10 = 0.02469648307522927, nDCL@10 = 0.0024464502508388963\n",
      "Test : HR@20 = 0.1055, MRR@20 = 0.0211, Coverage@20 = 0.2333, nDCG@20 = 0.034409123222778414, nDCL@20 = 0.004649546849046022\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU04z-n1-lwa"
   },
   "source": [
    "## Trigonometry scale attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJiHTF7_-lwb"
   },
   "outputs": [],
   "source": [
    "def rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pQN1IHU-lwc"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = rescale_score(i + 1), rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = diff / np.exp(diff) if i != j else 5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQtcfKcE-lwc",
    "outputId": "989556b9-ee77-47f7-ada3-7819ec240f68",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1441.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0343, MRR@5 == 0.0208, Coverage@5 = 0.1048\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1461\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0271, Coverage@20 = 0.2014\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0183, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0228, Coverage@10 = 0.1475\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0260, Coverage@20 = 0.2003\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1357.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0730, MRR@10 == 0.0243, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1258, MRR@20 == 0.0277, Coverage@20 = 0.2047\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1302.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0369, MRR@5 == 0.0198, Coverage@5 = 0.1150\n",
      "Validation : HR@10 = 0.0704, MRR@10 == 0.0242, Coverage@10 = 0.1541\n",
      "Validation : HR@20 = 0.1249, MRR@20 == 0.0278, Coverage@20 = 0.2096\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0009, MRR@5 == 0.0003, Coverage@5 = 0.1653\n",
      "Validation : HR@10 = 0.0018, MRR@10 == 0.0004, Coverage@10 = 0.2360\n",
      "Validation : HR@20 = 0.0026, MRR@20 == 0.0005, Coverage@20 = 0.3249\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:58<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0303 achieved with mlrank=(50, 50, 5)\n",
      "COV=0.1750 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1045.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 == 0.0103, Coverage@5 = 0.1287\n",
      "Test : HR@10 = 0.0589, MRR@10 == 0.0150, Coverage@10 = 0.1744\n",
      "Test : HR@20 = 0.0994, MRR@20 == 0.0177, Coverage@20 = 0.2338\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56vIkauV-lwd"
   },
   "outputs": [],
   "source": [
    "def center_and_rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AyRMQch-lwe",
    "outputId": "549aaf3d-a9ea-4476-b139-7e64607dbf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75657241 0.47457495 0.34571609 0.31110998]\n",
      " [0.75657241 1.         0.56009915 0.38898453 0.34571609]\n",
      " [0.47457495 0.56009915 1.         0.56009915 0.47457495]\n",
      " [0.34571609 0.38898453 0.56009915 1.         0.75657241]\n",
      " [0.31110998 0.34571609 0.47457495 0.75657241 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = center_and_rescale_score(i + 1), center_and_rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = 1 / (diff + 1)\n",
    "\n",
    "similarity = eucl_matrix\n",
    "        \n",
    "print(similarity)\n",
    "    \n",
    "a = np.linalg.cholesky(similarity)        \n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdXGb7Wb-lwf",
    "outputId": "604d12fb-6502-4041-cc4e-5c6d163c1254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1482.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0528, MRR@10 == 0.0222, Coverage@10 = 0.1530\n",
      "Validation : HR@20 = 0.0871, MRR@20 == 0.0245, Coverage@20 = 0.2168\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1424.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0192, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0235, Coverage@10 = 0.1505\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0270, Coverage@20 = 0.2039\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1415.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0197, Coverage@5 = 0.1139\n",
      "Validation : HR@10 = 0.0686, MRR@10 == 0.0246, Coverage@10 = 0.1552\n",
      "Validation : HR@20 = 0.1161, MRR@20 == 0.0279, Coverage@20 = 0.2110\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1366.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0187, Coverage@5 = 0.1164\n",
      "Validation : HR@10 = 0.0677, MRR@10 == 0.0239, Coverage@10 = 0.1596\n",
      "Validation : HR@20 = 0.1152, MRR@20 == 0.0272, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1312.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0180, Coverage@5 = 0.1109\n",
      "Validation : HR@10 = 0.0572, MRR@10 == 0.0217, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1099, MRR@20 == 0.0253, Coverage@20 = 0.2116\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:38<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0827 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0293 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1816 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1105.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0246, MRR@5 == 0.0129, Coverage@5 = 0.1312\n",
      "Test : HR@10 = 0.0554, MRR@10 == 0.0168, Coverage@10 = 0.1816\n",
      "Test : HR@20 = 0.0985, MRR@20 == 0.0198, Coverage@20 = 0.2454\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ5eMt1G-lwg"
   },
   "source": [
    "## Conditional prob attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2f472Za-lwg"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count12_tot = 0\n",
    "count12_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "     count12_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count12_loc += 1\n",
    "  count12_tot += count12_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvf78Rfb-lwh"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count13_tot = 0\n",
    "count13_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count13_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count13_loc += 1\n",
    "  count13_tot += count13_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJHQliXB-lwh"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count14_tot = 0\n",
    "count14_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count14_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count14_loc += 1\n",
    "  count14_tot += count14_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uc9cn3J-lwj"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count15_tot = 0\n",
    "count15_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count15_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count15_loc += 1\n",
    "  count15_tot += count15_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLXk6x4G-lwk"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count23_tot = 0\n",
    "count23_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count23_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count23_loc += 1\n",
    "  count23_tot += count23_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FlI1HRm-lwo"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count24_tot = 0\n",
    "count24_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count24_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count24_loc += 1\n",
    "  count24_tot += count24_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tawueqnY-lwq"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count25_tot = 0\n",
    "count25_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count25_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count25_loc += 1\n",
    "  count25_tot += count25_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-A4Q24n-lwu"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count34_tot = 0\n",
    "count34_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count34_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count34_loc += 1\n",
    "  count34_tot += count34_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3YNSNjX-lwv"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count35_tot = 0\n",
    "count35_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count35_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count35_loc += 1\n",
    "  count35_tot += count35_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AisgFMpm-lww"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count45_tot = 0\n",
    "count45_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count45_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "      count45_loc += 1\n",
    "  count45_tot += count45_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ_R_SJS-lwx"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1')\n",
    "users = train_new_part.userid.unique()\n",
    "count11_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count11_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBDskvQm-lwy"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count22_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count22_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YkuEEsn-lwy"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count33_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count33_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmfoz1Mw-lw0"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count44_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count44_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpfZSAEp-lw1"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count55_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count55_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri7dKAgV-lw2"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "rat_dist_matrix[0][0] = count11_tot\n",
    "rat_dist_matrix[0][1] = rat_dist_matrix[1][0]= count12_tot\n",
    "rat_dist_matrix[0][2] = rat_dist_matrix[2][0]= count13_tot\n",
    "rat_dist_matrix[0][3] = rat_dist_matrix[3][0]= count14_tot\n",
    "rat_dist_matrix[0][4] = rat_dist_matrix[4][0]= count15_tot\n",
    "rat_dist_matrix[1][1] = count22_tot\n",
    "rat_dist_matrix[1][2] = rat_dist_matrix[2][1] = count23_tot\n",
    "rat_dist_matrix[1][3] = rat_dist_matrix[3][1] = count24_tot\n",
    "rat_dist_matrix[1][4] = rat_dist_matrix[4][1] = count25_tot\n",
    "rat_dist_matrix[2][2] = count33_tot\n",
    "rat_dist_matrix[2][3] = rat_dist_matrix[3][2] = count34_tot\n",
    "rat_dist_matrix[2][4] = rat_dist_matrix[4][2] = count35_tot\n",
    "rat_dist_matrix[3][3] = count44_tot\n",
    "rat_dist_matrix[3][4] = rat_dist_matrix[4][3] = count45_tot\n",
    "rat_dist_matrix[4][4] = count55_tot       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9tfKojo-lw3"
   },
   "outputs": [],
   "source": [
    "summ = np.sum(rat_dist_matrix)\n",
    "rat_dist_matrix /= summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63xlkdVN-lw4"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix[0,0] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[1,1] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[2,2] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[3,3] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[4,4] += np.random.uniform(low=0.0, high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9_koO81-lw4"
   },
   "outputs": [],
   "source": [
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOP1rnpS-lw5",
    "outputId": "722042ce-74d0-4138-aaf3-9f15b38ed67e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1542.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0164, Coverage@5 = 0.0949\n",
      "Validation : HR@10 = 0.0554, MRR@10 == 0.0195, Coverage@10 = 0.1337\n",
      "Validation : HR@20 = 0.0880, MRR@20 == 0.0217, Coverage@20 = 0.1796\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1359.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0188, Coverage@5 = 0.0988\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0226, Coverage@10 = 0.1309\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0250, Coverage@20 = 0.1772\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1444.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0352, MRR@5 == 0.0207, Coverage@5 = 0.0993\n",
      "Validation : HR@10 = 0.0642, MRR@10 == 0.0245, Coverage@10 = 0.1315\n",
      "Validation : HR@20 = 0.1047, MRR@20 == 0.0273, Coverage@20 = 0.1777\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1446.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0334, MRR@5 == 0.0205, Coverage@5 = 0.1007\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0245, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0273, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1284.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0203, Coverage@5 = 0.1004\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1029, MRR@20 == 0.0272, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:55<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0800 achieved with mlrank=(45, 45, 5)\n",
      "Best MRR=0.0279 achieved with mlrank=(40, 45, 5)\n",
      "COV=0.1560 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1100.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0290, MRR@5 == 0.0126, Coverage@5 = 0.1161\n",
      "Test : HR@10 = 0.0528, MRR@10 == 0.0157, Coverage@10 = 0.1549\n",
      "Test : HR@20 = 0.1038, MRR@20 == 0.0190, Coverage@20 = 0.2077\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LaTTE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
